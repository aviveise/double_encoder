[hyper_parameters]
learning_rate: 1e-3
batch_size: 0.0025
epochs: 10
momentum: 0.5
layer_sizes: 512
method_in: tanh
method_out: none

[regularization_weight]
type: WeightDecayRegularization
weight: 0.05
zeroing_param: 0

[regularization_reconstruction]
type: ReconstructionRegularization
weight: 0
zeroing_param: 0

[regularization_weight_orthonormal]
type: WeightOrthonormalRegularization
weight: 0
zeroing_param: 0

[regularization_variance]
type: VarianceRegularization
weight: 10
zeroing_param : 1000

[output]
path: C:\Workspace\output
type: none
sample: 0
sample_number: 30000
fine_tune: 0
import_net: none