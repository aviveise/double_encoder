[hyper_parameters]
learning_rate: 0.001
batch_size: 0.007
epochs: 200
strategy: SGD
rho: 0.95
momentum: 0.5
layer_sizes: 1024 2048 1024
method_in: leakyrelu
method_out: none
cascade_train: 0
decay: [30, 60, 90, 120, 150, 180, 200]
decay_factor: 0.5

[regularization_weight]
type: WeightDecayRegularization
weight: 0.005
zeroing_param: 0

[regularization_reconstruction]
type: ReconstructionRegularization
weight: 0
zeroing_param: 0
recon_strategy: all
layer: 1

[regularization_variance]
type: VarianceRegularization
weight: 0
zeroing_param: 100000
layer: 1

;decorrelation regularization
[regularization_weight_orthonormal]
type: WeightOrthonormalRegularization
weight: 0
zeroing_param: 0

[regularization_sparse]
type: SparseRegularization
weight: 0
zeroing_param: 0
p: 0

[regularization_l2_hidden]
type: HiddenL2Regularization
weight: 1
layer: 1
zeroing_param: 0

[regularization_hinge]
type: HingeRegularization
weight: 0
k: 2
b: 1
eps: 1e-8
zeroing_param : 0
hinge_strategy: all
hinge_type: abs

[output]
path: C:\Workspace\output
type: none
sample: 0
sample_number: 0
fine_tune: 0
import_net: C:\Workspace\output\2015_09_07_08_44_06\double_encoder_2015_09_07_10_50_07_epoch_20.mat
verbosity=debug