[hyper_parameters]
learning_rate: 0.0001
batch_size: 0.004
epochs: 40
strategy: SGD
rho: 0.95
momentum: 0.5
layer_sizes: 2048 2048 2048
method_in: leakyrelu
method_out: none
cascade_train: 0
decay=[18,27,36]
decay_factor=0.1
validation_epoch=1
early_stopping=0
early_stopping_layer=0
early_stopping_metric=correlation

[regularization_weight]
type: WeightDecayRegularization
weight: 0.05
zeroing_param: 0

[regularization_reconstruction]
type: ReconstructionRegularization
weight: 0
zeroing_param: 0
recon_strategy: backward
layer: 1

[regularization_variance]
type: VarianceRegularization
weight: 0
zeroing_param: 0
layer: -1

;decorrelation regularization
[regularization_weight_orthonormal]
type: WeightOrthonormalRegularization
weight: 0
zeroing_param: 0

[regularization_sparse]
type: SparseRegularization
weight: 0
zeroing_param: 0
p: 0

[regularization_l2_hidden]
type: HiddenL2Regularization
weight: 1
layer: 1
zeroing_param: 0


[regularization_hinge]
type: HingeRegularization
weight: 0
k: 2
b: 1
eps: 1e-8
zeroing_param : 0
hinge_strategy: all
hinge_type: abs

[output]
path: C:\Workspace\output
type: none
sample: 0
sample_number: 0
fine_tune: 0
import_net: C:\Workspace\output\2015_10_09_18_56_43\double_encoder_2015_10_09_19_27_16_layer_4.mat
verbosity=debug